===============================
Data Integrity Testing with fio
===============================

Introduction
------------

fio is widely known as a performance benchmarking platform. But fio was
actually designed as a testing and validation tool for the Linux Block 
I/O subsystem. In this role fio provides extensive data integrity testing
(DIT) functionality, including a variety of verification modes and flexible
data pattern usage and hashing algorithms for quickly generating and
validating data written to devices under test (DUT). When these verification
features are combined with fio's extensive workload-generation functionality,
large custom matrices of test suites tailored to real-world scenarios can be
devised, everything from making sure your new SSD will reliably maintain the
data on your personal computer system, to mimicking the workload of a large
datacenter installation running hundreds of VMs.

In the first section of this guide we'll jump right into using fio's DIT
features to get you up and running as quickly as possible, with tips to avoid
some of the potential pitfalls in the myriad of fio's options. Once that's
established we'll step back to discuss various testing strategies to make sure
you're modeling your workloads productively to get the most bang for your buck
in terms of coverage and time. In the third and final section we'll go deep
into some unique testcases, including error injection and detection.

Part 1 - Using fio for DIT
--------------------------

Verify defined
~~~~~~~~~~~~~~

A "verify" operation is a read request issued to a block previously written by
fio, with the read payload compared against an expected data pattern. fio
employs a combination of data patterns and hashing digests to provide
high-performance byte-level corruption detection across the full contents of
the block.

fio doesn't verify data by default, owing to its primary role as a
benchmarking tool, where verifies would impact performance measurements.  When
enabled, fio can perform verification operations in any of the following three
stages of its operation:

	1. During a write workload ("in-workload")
	2. At the end of a write workload ("post-workload")
	3. During a read-only workload

A workload is defined using fio's large set of job-based parameters, which
include `readwrite=` (aka `rw=`), `size=`, `iodepth`, `numjobs`, etc..

A read-only workload is defined using `rw=read` (sequential reads) and
`rw=randread` (random reads).  A write-only workload is defined using
`rw=write` (sequential writes) and `rw=randwrite` (random writes). Mixed
read/write workloads can be defined using `rw=rw` (sequential reads+writes)
and `rw=randrw` (random reads+writes).

As presently implemented, fio will only verify data for read requests issued
by either read-only and write-only workloads. Reads issued by mixed read/write
workloads will not verify data. fio still supports verifies for mixed
workloads, but only for the reads issued by the verify logic, which operates
independently of the reads issued by the mixed workload itself. To understand
why this is the case it's helpful to describe how fio's verify feature is
implemented.

How fio performs verification 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When verifies are enabled (`verify=`), all writes generated by fio are logged
inside an in-memory binary tree. fio uses this tree to know which blocks to
verify during in-workload or post-workload verifies. Any reads generated by
mixed read/write workloads do not consult this tree, thus do not verify the
data read, even for blocks written by the same workload. Only reads generated
by the verify logic itself, sourced from the tree, will validate the data
read. In this respect the verify reads are "out-of-band" with respect to the
I/Os generated by workload. In fact, the verify reads generated during
in-workload and post-workload verifies are not counted in most of fio's
reported statistics.

Read-only workloads are handled differently - they assume all blocks
referenced by the read workload have been written by a previously-executed
write workload. This assumption allows fio to support independent
verification-only invocations, executed after a previous write-workload
invocation. This is useful for testing read-only DUTs and data-at-rest
scenarios. This assumption by fio mandates caution however - there are
combinations of options that will complete a write workload without writing
the full dataset defined by the workload. For example, random workloads using
an `io_size` (amount of data to write) that is smaller than the total range of
device blocks eligible for writes (`size`).  This scenario will result in
false-positive verification errors if the subsequent read-only verify workload
doesn't share the same repeatable random-number generation used to generate
the I/O request offsets and block counts (`randrepeat=1`), or if they don't
share the same I/O pattern (`rw=randwrite` and `rw=randread`) or same relevant
parameters like `bs`, `numjobs`, etc... We will cover these situations in this
guide. 

Primary verify options
~~~~~~~~~~~~~~~~~~~~~~

.. option:: verify=str

    Enables verification. This must be set for any of the other verification
    options to apply. Specifies which parts of blocks are verified and
	the hashing algorithm used to verify the body of the block. Some values
    include `md5`, `xxhash`, `crc64`, `sha256`, etc.

.. option:: verify_backlog=int

	Enables verify during write workloads. The value specified is the
	number of writes a workload will perform before those writes are verified.
	By default, fio will verify the data for all writes issued since the
	last backlog-based verify interval. For example, if `verify_backlog=8`,
	fio will issue 8 writes, followed by 8 verifies, followed by 8 more
	writes, etc...

.. option:: verify_backlog_batch=int

	The number of verifies performed at each `verify_backlog` interval.
	For example, if `verify_backlog=8` and `verify_backlog_batch=4`, fio
	will issue 8 writes, followed by 4 verifies, followed by 8 more writes.
	Specifying a `verify_backlog_batch` < `verify_backlog` causes fio to
	fall behind in verifying data, creating a progressively-larger "backlog"
	of data whose verification will be deferred to the post-workload verify
	stage. A value of zero or >= `verify_backlog` is the same as
	specifying no value (ie, all writes will be verified at every
	`verify_backlog` interval).
