===============================
Data Integrity Testing with fio
===============================

Introduction
------------

fio is widely known as a performance benchmarking platform. But fio was
actually designed as a testing and validation tool for the Linux Block I/O
subsystem. In this role fio provides extensive data integrity testing (DIT)
functionality, including a variety of verification modes and flexible data
pattern usage and hashing algorithms for quickly generating and validating
data written to devices under test (DUT). When these verification features are
combined with fio's extensive workload-generation functionality, large custom
matrices of test suites tailored to real-world scenarios can be devised,
everything from making sure your new SSD will reliably maintain the data on
your personal computer system, to mimicking the workload of a large datacenter
installation running hundreds of VMs.

In the first section of this guide we'll jump right into using fio's DIT
features to get you up and running as quickly as possible, with tips to avoid
some of the potential pitfalls in the myriad of fio's options. Once that's
established we'll step back to discuss various testing strategies to make sure
you're modeling your workloads productively to get the most bang for your buck
in terms of coverage and time. In the third and final section we'll go deep
into some unique testcases, including error injection and detection.

Part 1 - Using fio for DIT
--------------------------

Verify defined
~~~~~~~~~~~~~~

A "verify" operation is a read request issued to a block previously written by
fio, with the read payload compared against an expected data pattern. fio
employs a combination of data patterns and hashing digests to provide
high-performance byte-level corruption detection for the full contents of the
block.

fio doesn't verify data by default, owing to its primary role as a
benchmarking tool, where verifies would impact performance measurements.  When
enabled, fio can perform verification operations in any of the following three
stages of its operation:

	1. During a write workload ("in-workload")
	2. At the end of a write workload ("post-workload")
	3. During a read-only workload

A workload is by fio's job-based parameters, which include `readwrite=` (aka
`rw=`), `size=`, `iodepth`, `numjobs`, etc..

A read-only workload is defined using `rw=read` (sequential reads) and
`rw=randread` (random reads).  A write-only workload is defined using
`rw=write` (sequential writes) and `rw=randwrite` (random writes). Mixed
read/write workloads can be defined using `rw=rw` (sequential reads+writes)
and `rw=randrw` (random reads+writes).

As presently implemented, fio will only verify data for read requests issued
by either read-only and write-only workloads. Reads issued by mixed read/write
workloads will not verify data. fio still supports verifies for mixed
workloads, but only for the reads issued by the verify logic, which operates
independently of the reads issued by the mixed workload itself. To understand
why this is the case it's helpful to describe how fio's verify feature is
implemented.

How fio performs verification 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When verifies are enabled (`verify=`), all writes generated by fio are logged
inside an in-memory binary tree. fio uses this tree to know which blocks to
verify during in-workload or post-workload verifies. Any reads generated by
mixed read/write workloads do not consult this tree, thus do not verify the
data read, even for blocks written by the same workload. Only reads generated
by the verify logic itself, sourced from the tree, will validate the data
read.  In this respect the verify reads are "out-of-band" with respect to the
I/Os generated by workload.

Read-only workloads are handled differently - they assume all blocks referenced
by the read workload have been written by a previously-executed write workload.
This assumption allows fio to support independent verification-only
invocations, useful for testing read-only DUTs and data-at-rest scenarios. This
assumption also mandates caution however - there are combinations of options
that will complete a write workload without writing the full dataset defined by
the workload. For example, random workloads using an `io_size` (amount of data
to write) that is smaller than the total range of device blocks eligible for
writes (`size`).  This scenario will result in false-positive verification
errors if the subsequent read-only verify workload doesn't share the same
random-number generation used to generate I/O request offsets and block counts
(`randrepeat=1`), or if they don't share the same I/O pattern (`rw=randwrite`
and `rw=randread`) or same relevant parameters like `bs`. We will cover these
situations in this guide.

Primary verify options
~~~~~~~~~~~~~~~~~~~~~~

.. option:: verify=str

	Enables verification. *This must be set for any of the other verification
	options below to apply*. Specifies which parts of blocks are verified and
	the hashing algorithm used to verify the body of the block. Some values
	include `md5`, `xxhash`, `crc64`, `sha256`, etc.

.. option:: verify_backlog=int

	Enables in-workload verifications for write workloads. The value specified
	is the number of writes a workload will perform before those writes are
	verified.  When set without `verify_backlog_batch`, fio will verify the
	data for all writes issued since the last backlog-based verify interval.
	For example, if `verify_backlog=8`, fio will issue 8 writes, followed by 8
	verifies, followed by 8 more writes, etc... 

.. option:: verify_backlog_batch=int

	The number of verifies performed whenever the number of unverified writes
	is at `verify_backlog`.  For example, if `verify_backlog=8` and
	`verify_backlog_batch=2`, fio will issue 8 writes, followed by 2 verifies,
	which drops the number of unverified writes from 8 to 6, allowing 2 more
	writes to be issued, after which 2 more verifies will be performed, and
	the pattern of 2 writes followed by 2 verifies will repeat until the end
	of the workload.  Specifying a `verify_backlog_batch` < `verify_backlog`
	causes fio to fall behind in verifying data, creating a "backlog" of data
	whose verification will be deferred to the post-workload verify stage. A
	value of zero or >= `verify_backlog` is the same as specifying no value
	(ie, all writes will be verified at every `verify_backlog` interval).

Secondary verify options (used less often)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. option:: do_verify=bool

    Enables in-workload and post-workload verifies. Default is true whenever
    verify is enabled. If false, only verifies for read-only workloads will be
    enabled. 

.. option:: verify_only

	Treat all write workloads as read-only workloads. This is convenience
	option that lets you share the exact same job specification parameters
	between your write and verify workloads, differentiating them with this
	option rather than having to change the `rw=` value from write to read. 

